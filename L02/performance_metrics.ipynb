{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "There are a number of frequently uses metrics in ML, namely accuracy, precision, recall and the $F_1$ score. All are called _metrics_ (though they are not true norms, like ${\\cal L}_2$ or ${\\cal L}_1$ we saw last time).\n",
    "\n",
    "Maybe performance _score_ would be a better name than performance metric, at least for the accuracy, precision, recall we will be looking at---emphasising the conceptual distinction between the  _score-function_ and _cost(/loss/error/objective)-function_ (the later is typically a true distance/norm function).  \n",
    "\n",
    "You can find a lot of details on say precision and recall in Wikipedia\n",
    "\n",
    ">  https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "\n",
    "### Nomenclature\n",
    "\n",
    "| NAME | SYMBOL | ALIAS |\n",
    "| :---: | :---: | :---: |\n",
    "|true positives | $TP$ | |\n",
    "|true negatives | $TN$ | |\n",
    "|false positives| $FP$ | type I error| \n",
    "|false negatives| $FN$ | type II error |\n",
    "\n",
    "and $N = N_P + N_N$ being the total number of samples and the number of positive and negative samples\n",
    "respectively.\n",
    "\n",
    "### Precision\n",
    "\n",
    "$$\n",
    "\\def\\by{\\mathbf{y}}\n",
    "\\def\\ba{\\begin{array}{lll}}\n",
    "\\def\\ea{\\end{array}}\n",
    "\\newcommand{\\rem}[1]{}\n",
    "\\newcommand\\st[1]{_{\\scriptsize #1}}\n",
    "\\newcommand\\myfrac[2]{\\frac{#1\\rule{0pt}{8pt}}{#2\\rule{0pt}{8pt}}} \n",
    "\\ba\n",
    " p &= \\myfrac{TP}{TP + FP}\n",
    "\\ea\n",
    "$$\n",
    "\n",
    "### Recall or Sensitivity\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "    r &= \\myfrac{TP}{TP + FN}\\\\\n",
    "      &= \\myfrac{TP}{N_P}\n",
    "  \\ea\n",
    "$$\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "      a &= \\myfrac{TP + TN}{TP + TN + FP + FN}\\\\\n",
    "        &= \\myfrac{TP + TN}{N}\\\\\n",
    "        &= \\myfrac{TP + TN}{N_P~~ + N_N} \n",
    "  \\ea\n",
    "$$\n",
    "\n",
    "#### Accuracy Paradox\n",
    "\n",
    "A static constant model, say $p\\st{cancer}=0$ may have higher accuracy than a real model with predictive power. This is odd!\n",
    "\n",
    "Asymmetric weights could also be associated with the false positive and false negative predictions, yielding either FP of FN much more expensive than the other. Say, it is more expensive not to treat a person with cancer, than treating a person without cancer. \n",
    "\n",
    "### F-score\n",
    "\n",
    "General $\\beta$-harmonic mean of the precision and recall \n",
    "$$\n",
    "    F_\\beta = (1+\\beta^2) \\myfrac{pr}{\\beta^2 p+r}\\\\\n",
    "$$ \n",
    "that for say $\\beta=2$ or $\\beta=0.5$ shifts or skews the emphasis on the two variables in the equation. Normally only the $\\beta=1$ harmonic mean is used\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "    F_1 &= \\myfrac{2pr}{p+r}\\\\\n",
    "        &= \\myfrac{2}{1/p + 1/r}\n",
    "  \\ea\n",
    "$$\n",
    "with $F$ typically being synonymous with $F_1$. \n",
    "\n",
    "If needed, find more info on Wikipedia\n",
    "\n",
    "> https://en.wikipedia.org/wiki/F1_score\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "For statistical classification, the confusion matrix or error matrix (or\n",
    "matching matrix in unsupervised learning) is for a two-class problem given by\n",
    "the $2\\times2$ matrix with dimensions 'actual' and 'predicted'\n",
    "\n",
    "$$   \n",
    "{\\bf M}\\st{confusion} = \n",
    "\\begin{array}{l|ll}\n",
    "                           & \\mbox{actual true} & \\mbox{actual false} \\\\ \\hline\n",
    "    \\mbox{predicted true}  & TP & FP \\\\     \n",
    "    \\mbox{predicted false} & FN & TN \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The diagonal, in the square matrix, represent predicted values being the same\n",
    "as the actual values, off-diagonal elements represent erroneous prediction.\n",
    "\n",
    "Also notice, that the layout of this matrix is different of what is given in [HOML], \"Confusion Matrix\", p.110/fig 3-3. This is just a minor issue, since we can always flip/rotate/transpose the matrix (say by flipping the $\\by\\st{true}$ and $\\by\\st{pred}$ arguments). \n",
    "\n",
    "For N-class classification the matrix gives a matrix with $N$ actual\n",
    "classes and $N$ predicted classes\n",
    "\n",
    "$$\n",
    "{\\bf M}\\st{confusion}~~~ =\n",
    "  \\left[\n",
    "  \\begin{array}{llll}\n",
    "       c_{11} & c_{12} & \\cdots & c_{1n} \\\\ \n",
    "       c_{21} & c_{22} & \\cdots & c_{2n} \\\\\n",
    "       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "       c_{n1} & c_{n2} & \\cdots & c_{nn} \\\\ \n",
    "  \\end{array}\n",
    "  \\right]\n",
    "$$\n",
    "with say element $c_{21}$ being the number of actual classes '1' being predicted (erroneously) as class '2'.\n",
    "\n",
    "### Nomenclature for the Confusion Matrix\n",
    "\n",
    "The naming of the elements in the confusion matrix can be rather exotic, like _false omission rate_ (see the figure below), but we won't get to such detail here...let us stick with TP, TN, FP, FN and $F_1$!\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L02/Figs/performance_metrics.jpg\" alt=\"WARNING: could not get image from server\" style=\"width:900px\">\n",
    "\n",
    "If you need more info on the confusion matrix:\n",
    "\n",
    ">  https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "#### Qa Implement the Accuracy function and test it on the MNIST data.\n",
    "\n",
    "We now follow the convention in Scikit-learn, that a score funtion takes the arguments `y_true` and then `y_pred`\n",
    "\n",
    "```\n",
    "    sklearn.metrics.accuracy_score(y_true, y_pred, ..)\n",
    "```\n",
    "\n",
    "Implement a general accuracy function `MyAccuracy(y_true, y_pred)`. Again, implement the function you self from scratch, i.e. do not use any helper functions from Scikit-learn (implementing via `sklearn.metrics.confusion_matrix` is also not allowed, othewise you will then learn nothing!)\n",
    "\n",
    "Reuse your MNIST data loader and test the `MyAccuracy` function  both on your dummy classifier and on the Stochastic Gradient Descent classifier (with setup parameters as in [HOML]).\n",
    "\n",
    "Compare your accuracy score with the acutal value from `sklearn.metrics.accuracy_score()`.\n",
    "\n",
    "(Implementation note: what do you do, if the denominator is zero?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 70000\n",
      "Label of the digit: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to fetch the MNIST dataset\n",
    "def MNIST_GetDataSet():\n",
    "    X,y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame = False)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "# Function to plot a digit\n",
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Fetches X and y\n",
    "X,y = MNIST_GetDataSet()\n",
    "\n",
    "#Convert to [0;1] via scaling\n",
    "X = X / 255.\n",
    "\n",
    "#Check if data is loaded\n",
    "print(\"Number of samples:\", len(X))\n",
    "\n",
    "\n",
    "digit_to_plot = X[9]  # The index is 9 for the 10th digit (0-based index)\n",
    "\n",
    "#Check what number the image is representing\n",
    "print(\"Label of the digit:\", y[9])\n",
    "\n",
    "MNIST_PlotDigit(digit_to_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(70000, 784)\n",
      "Predicted Label: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: False\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAG3UlEQVR4nO3cPY9OWwCG4XeYQtBMIQqNbloaJS2hkkx0/oHWD+EPqLQKhUohEgqFz0So6EwUKhqSfRq5q/ORtR37HTPX1T9Zu7v3atbGNE3TCgBWq9WhdX8AAHuHKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgGyu+wPgoHn//v2s3fb29vDm1q1bw5sbN24Mb9g/3BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEA8iAcLe/78+azdoUPj/3CnTp2adRYHl5sCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIB/FgYS9evJi1O378+PDm6tWrs87i4HJTACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8SAe/ILXr18Pb27fvj3rrOvXr8/awQg3BQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIF5JhV/w7t274c3Xr19nnXXt2rVZOxjhpgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFALIxTdO07o+AP9W5c+eGN58/f5511ps3b4Y3x44dm3UWB5ebAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyOa6PwD2ig8fPgxvnj17NrzZ3t4e3qxWHrdjGW4KAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgHsSDnx49erTIOSdOnFjkHJjDTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIhXUuGnV69eLXLOzZs3FzkH5nBTACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA2ZimaVr3R8D/7enTp8Oby5cvD29Onz49vHny5MnwZrVarY4cOTJrByPcFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQDbX/QHwOzx8+HB48+XLl+HNxYsXhzcetmMvc1MAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgDxIB770suXLxc5Z2dnZ5FzYCluCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIBvTNE3r/gj4N58+fRrenDlzZniztbU1vHn79u3wBvYyNwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCb6/4A+C937twZ3uzu7g5vLl26NLyB/cZNAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAxIN47HkfP35c5Jytra1FzoG9zE0BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDEg3jseffv31/knCtXrixyDuxlbgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACAexGMxjx8/nrXb3d39n78E+CduCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIB7EYzH37t2btfvx48fw5uzZs8ObCxcuDG9gv3FTACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUA4pVUZvn27dvw5sGDB7/hS/7ezs7O8Obw4cO/4Uvgz+KmAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsjFN07Tuj+DP8/379+HN+fPnZ5118uTJ4c3du3eHN0ePHh3ewH7jpgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAOJBPADipgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMhfdQh9GvL1MhkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: add your code here..\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#reshapes X to 2D array if not already\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# Create binary target variable y_train_5 with the digit '5' as true\n",
    "y_train_5 = (y_train == '5')   # True for all 5s, False for all other digits\n",
    "# Create binary target variable for the testing set\n",
    "y_test_5  = (y_test == '5')\n",
    "\n",
    "# Create a SGDClassifier which will classify if a digit is a 5 or not\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier using the training data\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "classified_numbers = np.where(y_pred == y_test_5)[0]\n",
    "\n",
    "for number in classified_numbers[:3]:\n",
    "    MNIST_PlotDigit(X_test[number])\n",
    "    # Predict if the digit is a 5 or not\n",
    "    prediction = sgd_clf.predict([X_test[number]])  # Provide the data sample\n",
    "    print(f\"Predicted Label: {prediction[0]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my a          =0.75\n",
      "scikit-learn a=0.75\n",
      "\n",
      "my a          =0.9769\n",
      "scikit-learn a=0.9769\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa...\n",
    "\n",
    "#from sklearn.base import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def MyAccuracy(y_true, y_pred):\n",
    "    if len(y_true)==0 or len(y_pred)==0:\n",
    "        return 0\n",
    "    y_correctPred=[]\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==y_pred[i]:\n",
    "            y_correctPred.append(y_pred[i])\n",
    "    return len(y_correctPred)/len(y_true)\n",
    "\n",
    "\n",
    "    \n",
    "# TEST FUNCTION: example of a comperator, using Scikit-learn accuracy_score\n",
    "def TestAccuracy(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "      print(\"Error: Input arrays have different lengths.\")\n",
    "      return\n",
    "    a0=MyAccuracy(y_true, y_pred)\n",
    "    a1=accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nmy a          ={a0}\")\n",
    "    print(f\"scikit-learn a={a1}\")\n",
    "\n",
    "TestAccuracy([1,2,3,4], [1,2,3,3])\n",
    "\n",
    "TestAccuracy(y_test_5, y_pred)\n",
    "#    # do some numerical comparison here, like\n",
    "#    #  if fabs(a0-a1)<eps then .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb Implement Precision, Recall and $F_1$-score and test it on the MNIST data for both the SGD and Dummy classifier models\n",
    "\n",
    "Now, implement the `MyPrecision`, `MyRecall` and `MyF1Score` functions, again taking MNIST as input, using the SGD and the Dummy classifiers and make some test vectors to compare to the functions found in Scikit-learn...\n",
    "\n",
    "(Implementation note: as before, what do you do, if the denominator is zero?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my p        =0.6666666666666666\n",
      "scikit-learn p=0.6666666666666666\n",
      "\n",
      "my p        =0.9460188933873145\n",
      "scikit-learn p=0.9460188933873145\n",
      "\n",
      "my r        =0.75\n",
      "scikit-learn r=0.75\n",
      "\n",
      "my r        =0.7858744394618834\n",
      "scikit-learn r=0.7858744394618834\n",
      "\n",
      "my f        =0.8571428571428572\n",
      "scikit-learn f=0.8571428571428571\n",
      "\n",
      "my f        =0.8585425597060624\n",
      "scikit-learn f=0.8585425597060625\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qb..\n",
    "import sklearn.metrics as metrics\n",
    "def MyPrecision(y_true, y_pred):\n",
    "    #predicted correct positive\n",
    "    pcp = [item for item in y_pred if item == True]\n",
    "    y_correctPred=[]\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==True and y_pred[i]==True:\n",
    "            y_correctPred.append(y_pred[i])\n",
    "    return len(y_correctPred)/len(pcp)\n",
    "\n",
    "def TestPrecision(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "      print(\"Error: Input arrays have different lengths.\")\n",
    "      return\n",
    "    p0=MyPrecision(y_true, y_pred)\n",
    "    p1=metrics.precision_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nmy p        ={p0}\")\n",
    "    print(f\"scikit-learn p={p1}\")\n",
    "\n",
    "TestPrecision([True,True,False,True], [True,True,True,False])\n",
    "TestPrecision(y_test_5, y_pred)\n",
    "\n",
    "\n",
    "def MyRecall(y_true, y_pred):\n",
    "    #condition positive\n",
    "    cp = [item for item in y_true if item == True]\n",
    "    y_correctPred=[]\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==True and y_pred[i]==True:\n",
    "            y_correctPred.append(y_pred[i])\n",
    "    return len(y_correctPred)/len(cp)\n",
    "\n",
    "def TestRecall(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "      print(\"Error: Input arrays have different lengths.\")\n",
    "      return\n",
    "    r0=MyRecall(y_true, y_pred)\n",
    "    r1=metrics.recall_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nmy r        ={r0}\")\n",
    "    print(f\"scikit-learn r={r1}\")\n",
    "\n",
    "TestRecall([True,True,True,True], [True,True,True,False])\n",
    "TestRecall(y_test_5, y_pred)\n",
    "    \n",
    "def MyF1Score(y_true, y_pred):\n",
    "    p = MyPrecision(y_true, y_pred)\n",
    "    r = MyRecall(y_true, y_pred)\n",
    "    return 2/((1/p)+(1/r))\n",
    "\n",
    "def TestF1Score(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "      print(\"Error: Input arrays have different lengths.\")\n",
    "      return\n",
    "    f0=MyF1Score(y_true, y_pred)\n",
    "    f1=metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nmy f        ={f0}\")\n",
    "    print(f\"scikit-learn f={f1}\")\n",
    "\n",
    "TestF1Score([True,True,True,True], [True,True,True,False])\n",
    "TestF1Score(y_test_5, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc The Confusion Matrix\n",
    "\n",
    "Revisit your solution to Qb in the `dummy_classifier.ipynb`. Generate the confusion matrix for both the Dummy and the SGD classifier using the `scklearn.metrics.confusion_matrix` function. \n",
    "\n",
    "I got the two confusion matrices\n",
    "\n",
    "```\n",
    "M_dummy=[[18166     0]\n",
    "        [ 1834     0]]\n",
    "   \n",
    "M_SDG=[[17618   548]\n",
    "      [  267  1567]]\n",
    "\n",
    "```\n",
    "your data may look similar (but not 100% equal).\n",
    "\n",
    "How are the Scikit-learn confusion matrix organized, where are the TP, FP, FN and TN located in the matrix indices, and what happens if you mess up the parameters calling\n",
    "\n",
    "```python\n",
    "confusion_matrix(y_test_5_pred, y_test5)\n",
    "```\n",
    "\n",
    "instead of \n",
    "```python\n",
    "confusion_matrix(y_test_5, y_test_5_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qc\n",
    "assert False, \"TODO: solve Qc, and remove me.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qd A Confusion Matrix Heat-map\n",
    "\n",
    "Generate a _heat map_ image for the confusion matrices, `M_dummy` and `M_SGD` respectively, getting inspiration from [HOML] \"Error Analysis\", pp.122-125.\n",
    "\n",
    "This heat map could be an important guide for you when analysing multiclass data in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qd\n",
    "assert False, \"TODO: solve Qd, and remove me.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qe Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qe concluding remarks in text.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2018-12-19| CEF, initial.\n",
    "2018-02-07| CEF, updated.\n",
    "2018-02-07| CEF, rewritten accuracy paradox section.\n",
    "2018-03-05| CEF, updated with SHN comments.\n",
    "2019-09-01| CEF, updated for ITMAL v2.\n",
    "2019-09-04| CEF, updated for print-f and added conclusion Q.\n",
    "2020-01-25| CEF, F20 ITMAL update.\n",
    "2020-02-03| CEF, minor text fixes.\n",
    "2020-02-04| CEF, updated page numbers to HOMLv2.\n",
    "2020-02-17| CEF, added implementation note on denominator=0.\n",
    "2020-09-03| CEF, E20 ITMAL update, udpated figs paths.\n",
    "2020-09-06| CEF, added alt text.\n",
    "2020-09-07| CEF, updated HOML page refs.\n",
    "2020-09-21| CEF, fixed factor 2 error in beta-harmonic.\n",
    "2021-01-12| CEF, F21 ITMAL update, moved revision tabel.\n",
    "2021-08-02| CEF, update to E21 ITMAL.\n",
    "2022-01-25| CEF, update to F22 STMAL.\n",
    "2023-02-07| CEF, update HOML page numbers.\n",
    "2023-02-09| CEF, chagned y_train to y_test in conf. matrix call.\n",
    "2023-08-30| CEF, minor table change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
