{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Training a Linear Regressor I \n",
    "\n",
    "The goal of the linear regression is to find the argument $w$ that minimizes the sum-of-squares error over all inputs. \n",
    "\n",
    "$$\n",
    "    \\providecommand\\rem[1]{}\n",
    "    \\rem{ITMAL: CEF def and LaTeX commands, remember: no newlines in defs}\n",
    "    \\providecommand\\eq[2]{#1 &=& #2\\\\}\n",
    "    \\providecommand\\ar[2]{\\begin{array}{#1}#2\\end{array}}\n",
    "    \\providecommand\\ac[2]{\\left[\\ar{#1}{#2}\\right]}\n",
    "    \\providecommand\\st[1]{_{\\textrm{\\scriptsize #1}}}\n",
    "    \\providecommand\\norm[1]{{\\cal L}_{#1}}\n",
    "    \\providecommand\\obs[2]{#1_{\\textrm{\\scriptsize obs}}^{\\left(#2\\right)}}\n",
    "    \\providecommand\\diff[1]{\\mathrm{d}#1}\n",
    "    \\providecommand\\pown[1]{^{(#1)}}\n",
    "    \\def\\pownn{\\pown{n}}\n",
    "    \\def\\powni{\\pown{i}}\n",
    "    \\def\\powtest{\\pown{\\textrm{\\scriptsize test}}}\n",
    "    \\def\\powtrain{\\pown{\\textrm{\\scriptsize train}}}\n",
    "    \\def\\bX{\\mathbf{M}}\n",
    "    \\def\\bX{\\mathbf{X}}\n",
    "    \\def\\bZ{\\mathbf{Z}}\n",
    "    \\def\\bw{\\mathbf{m}}\n",
    "    \\def\\bx{\\mathbf{x}}\n",
    "    \\def\\by{\\mathbf{y}}\n",
    "    \\def\\bz{\\mathbf{z}}\n",
    "    \\def\\bw{\\mathbf{w}}\n",
    "    \\def\\btheta{{\\boldsymbol\\theta}}\n",
    "    \\def\\bSigma{{\\boldsymbol\\Sigma}}\n",
    "    \\def\\half{\\frac{1}{2}}\n",
    "    \\providecommand\\pfrac[2]{\\frac{\\partial~#1}{\\partial~#2}}\n",
    "    \\providecommand\\dfrac[2]{\\frac{\\mathrm{d}~#1}{\\mathrm{d}#2}}\n",
    "\\bX =\n",
    "        \\ac{cccc}{\n",
    "            x_1\\pown{1} & x_2\\pown{1} & \\cdots & x_d\\pown{1} \\\\\n",
    "            x_1\\pown{2} & x_2\\pown{2} & \\cdots & x_d\\pown{2}\\\\\n",
    "            \\vdots      &             &        & \\vdots \\\\\n",
    "            x_1\\pownn   & x_2\\pownn   & \\cdots & x_d\\pownn\\\\\n",
    "        }\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### Qa Write a Python function that uses the closed-form to find $\\bw^*$\n",
    "\n",
    "We are going mto make a function `GetTheNormalEquation(X, y)`. The function takes a training dataset, where we have the matrix`X` and the vector of the label `y` and returns the `w` via the closed-form. \n",
    "\n",
    "The function is going to to use the normal equation as presented below:\n",
    "\n",
    "$$\n",
    "\\bw^* ~=~ \\left( \\bX^\\top \\bX \\right)^{-1} \\bX^\\top \\by\n",
    "$$\n",
    "\n",
    "Inside the function we make a variable called X_b which is the concatenate column of ones to X. In other words it is to add the bias term. \n",
    "\n",
    "\n",
    "Use the test data, `X` and `y` in the code below to find `w` via the closed-form. Use the test vectors for `w` to test your implementation, and remember to add the bias term (concat an all-one vector to `X` before solving). \n",
    "\n",
    "The next line where we store variable `w` we simply use the normal equation. It constists of multiple parts. The  `np.linalg.inv()` calculates the inverse of the matrix obtained from the \n",
    "$$\n",
    "\\left( \\bX^\\top \\bX \\right)^{-1}\n",
    "$$. \n",
    "\n",
    "The product of `np.linalg.inv()` is multiplied with the the rest, which is the transpose of the input data matrix with the target output vector. It results in a vector of size \\(d+1\\).\n",
    "\n",
    "$$\n",
    " \\bX^\\top \\by\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AssertInRange', 'CheckFloat', 'DToXy', 'GenerateConfusionMatrix', 'GenerateResults', 'InRange', 'Iterable', 'ListToMatrix', 'ListToVector', 'PrintMatrix', 'ResetRandom', 'ShowResult', 'TEST', 'TestAll', 'TestCheckFloat', 'TestPrintMatrix', 'TestVarName', 'VarName', 'XyToD', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__warningregistry__', 'ctxlib', 'inf', 'inspect', 'isFloat', 'isList', 'isNumpyArray', 'nan', 'np', 'random', 're', 'sklearn']\n",
      "[[1.00000000e+00 8.34044009e-01]\n",
      " [1.00000000e+00 1.44064899e+00]\n",
      " [1.00000000e+00 2.28749635e-04]\n",
      " [1.00000000e+00 6.04665145e-01]]\n",
      "w=[4.046879011698 1.880121487278]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.expanduser('../'))\n",
    "import numpy as np\n",
    "from libitmal import utils as itmalutils\n",
    "\n",
    "def GetOS():\n",
    "    return dir if os.name == 'nt' else ls\n",
    "\n",
    "# The Normal Equation p.134\n",
    "def GetTheNormalEquation(X, y):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Concatenate a column of ones to X\n",
    "    w = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "    return w\n",
    "\n",
    "def GenerateData():\n",
    "    X = np.array([[8.34044009e-01],[1.44064899e+00],[2.28749635e-04],[6.04665145e-01]])\n",
    "    y = np.array([5.97396028, 7.24897834, 4.86609388, 3.51245674])\n",
    "    return X, y\n",
    "\n",
    "X, y = GenerateData()\n",
    "#assert False, \"find the least-square solution for X and y, your implementation here, say from [HOML, p.114 2nd./p.134 3rd.]\"\n",
    "\n",
    "w = GetTheNormalEquation(X, y)\n",
    "\n",
    "\n",
    "# TEST VECTOR:\n",
    "w_expected = np.array([4.046879011698, 1.880121487278])\n",
    "itmalutils.PrintMatrix(w, label=\"w=\", precision=12)\n",
    "itmalutils.AssertInRange(w, w_expected, eps=1E-9)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb Find the limits of the least-square method\n",
    "\n",
    "Again find the least-square optimal value for `w` now using then new `X` and `y` as inputs.\n",
    "\n",
    "Describe the problem with the matrix inverse, and for what `M` and `N` combinations do you see, that calculation of the matrix inverse takes up long time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerateData(M=20, N=20)...\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bjark\\source\\repos\\MAL\\mal12\\L05\\linear_regression_1.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m X, y\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m X, y \u001b[39m=\u001b[39m GenerateData(M\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, N\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m w \u001b[39m=\u001b[39m GetOptiomalWeights(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Print w\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m itmalutils\u001b[39m.\u001b[39mPrintMatrix(w, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mw=\u001b[39m\u001b[39m\"\u001b[39m, precision\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Bjark\\source\\repos\\MAL\\mal12\\L05\\linear_regression_1.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGetOptiomalWeights\u001b[39m(X, y):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     X_b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mc_[np\u001b[39m.\u001b[39mones((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m)), X]  \u001b[39m# Concatenate a column of ones to X\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(X_b\u001b[39m.\u001b[39;49mT\u001b[39m.\u001b[39;49mdot(X_b))\u001b[39m.\u001b[39mdot(X_b\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mdot(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bjark/source/repos/MAL/mal12/L05/linear_regression_1.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m w\n",
      "File \u001b[1;32mc:\\Users\\Bjark\\source\\repos\\MAL\\MAL\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    562\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Bjark\\source\\repos\\MAL\\MAL\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# TODO: Qb...\n",
    "def GenerateData(M, N):\n",
    "    # TEST DATA: Matrix, taken from [HOML]\n",
    "    print(f'GenerateData(M={N}, N={N})...')\n",
    "    \n",
    "    assert M>0\n",
    "    assert N>0\n",
    "    assert isinstance(M, int)\n",
    "    assert isinstance(N, int)\n",
    "\n",
    "    # NOTE: not always possible to invert a random matrix; \n",
    "    #       it becomes sigular, hence a more elaborate choice \n",
    "    #       of values below (but still a hack): \n",
    "    X=2 * np.ones([M, N])\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i,0]=i*4\n",
    "    for j in range(X.shape[1]):\n",
    "        X[0,j]=-j*4\n",
    "\n",
    "    y=4 + 3*X + np.random.randn(M,1)\n",
    "    y=y[:,0] # well, could do better here!\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = GenerateData(M=10000, N=20)\n",
    "\n",
    "w = GetTheNormalEquation(X, y)\n",
    "\n",
    "# Print w\n",
    "itmalutils.PrintMatrix(w, label=\"w=\", precision=12)\n",
    "\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2018-12-18| CEF, initial.\n",
    "2018-02-14| CEF, major update.\n",
    "2018-02-18| CEF, fixed error in nabla expression.\n",
    "2018-02-18| CEF, added minimization plot.\n",
    "2018-02-18| CEF, added note on argmin/max.\n",
    "2018-02-18| CEF, changed concave to convex.\n",
    "2021-09-26| CEF, update for ITMAL E21.\n",
    "2011-10-02| CEF, corrected page numbers for HOML v2 (109=>114).\n",
    "2022-03-09| CEF, elaboreted on code and introduced GetData().\n",
    "2023-02-22| CEF, updated page no to HOML 3rd. ed., updated to SWMAL F23.\n",
    "2023-09-19| CEF, changed LaTeX mbox and newcommand (VSCode error) to textrm/mathrm and renewcommand.\n",
    "2023-09-28| CEF, elaborated on L-expressions from (..)^2 to \\|\\| .. \\|\\|_2^2.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
