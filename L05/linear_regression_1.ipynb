{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Training a Linear Regressor I \n",
    "\n",
    "The goal of the linear regression is to find the argument $w$ that minimizes the sum-of-squares error over all inputs. \n",
    "\n",
    "$$\n",
    "    \\def\\rem#1{}\n",
    "    \\rem{ITMAL: CEF def and LaTeX commands, remember: no  newlines in defs}\n",
    "    \\def\\eq#1#2{#1 &=& #2\\\\}\n",
    "    \\def\\ar#1#2{\\begin{array}{#1}#2\\end{array}}\n",
    "    \\def\\ac#1#2{\\left[\\ar{#1}{#2}\\right]}\n",
    "    \\def\\st#1{_{\\textrm{\\scriptsize #1}}}\n",
    "    \\def\\norm#1{{\\cal L}_{#1}}\n",
    "    \\def\\obs#1#2{#1_{\\textrm{\\scriptsize obs}}^{\\left(#2\\right)}}\n",
    "    \\def\\diff#1{\\mathrm{d}#1}\n",
    "    \\def\\pown#1{^{(#1)}}\n",
    "    \\def\\pownn{\\pown{n}}\n",
    "    \\def\\powni{\\pown{i}}\n",
    "    \\def\\powtest{\\pown{\\textrm{\\scriptsize test}}}\n",
    "    \\def\\powtrain{\\pown{\\textrm{\\scriptsize train}}}\n",
    "    \\def\\bX{\\mathbf{M}}\n",
    "    \\def\\bX{\\mathbf{X}}\n",
    "    \\def\\bZ{\\mathbf{Z}}\n",
    "    \\def\\bw{\\mathbf{m}}\n",
    "    \\def\\bx{\\mathbf{x}}\n",
    "    \\def\\by{\\mathbf{y}}\n",
    "    \\def\\bz{\\mathbf{z}}\n",
    "    \\def\\bw{\\mathbf{w}}\n",
    "    \\def\\btheta{{\\boldsymbol\\theta}}\n",
    "    \\def\\bSigma{{\\boldsymbol\\Sigma}}\n",
    "    \\def\\half{\\frac{1}{2}}\n",
    "    \\def\\pfrac#1#2{\\frac{\\partial~#1}{\\partial~#2}}\n",
    "    \\def\\dfrac#1#2{\\frac{\\mathrm{d}~#1}{\\mathrm{d}#2}}\n",
    "\\bw^* ~=~ \\left( \\bX^\\top \\bX \\right)^{-1} \\bX^\\top \\by\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "#### Qa Write a Python function that uses the closed-form to find $\\bw^*$\n",
    "\n",
    "We are going mto make a function `GetTheNormalEquation(X, y)`. The function takes a training dataset, where we have the matrix`X` and the vector of the label `y` and returns the `w` via the closed-form. \n",
    "\n",
    "The function is going to to use the normal equation as presented below:\n",
    "\n",
    "$$\n",
    "\\bw^* ~=~ \\left( \\bX^\\top \\bX \\right)^{-1} \\bX^\\top \\by\n",
    "$$\n",
    "\n",
    "Inside the function we make a variable called X_b which is the concatenate column of ones to X. In other words it is to add the bias term. \n",
    "\n",
    "\n",
    "Use the test data, `X` and `y` in the code below to find `w` via the closed-form. Use the test vectors for `w` to test your implementation, and remember to add the bias term (concat an all-one vector to `X` before solving). \n",
    "\n",
    "The next line where we store variable `w` we simply use the normal equation. It constists of multiple parts. The  `np.linalg.inv()` calculates the inverse of the matrix obtained from the \n",
    "$$\n",
    "\\left( \\bX^\\top \\bX \\right)^{-1}\n",
    "$$. \n",
    "\n",
    "The product of `np.linalg.inv()` is multiplied with the the rest, which is the transpose of the input data matrix with the target output vector. It results in a vector of size \\(d+1\\).\n",
    "\n",
    "$$\n",
    " \\bX^\\top \\by\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=[4.046879011698 1.880121487278]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.expanduser('../'))\n",
    "import numpy as np\n",
    "from libitmal import utils as itmalutils\n",
    "\n",
    "def GetOS():\n",
    "    return dir if os.name == 'nt' else ls\n",
    "\n",
    "# The Normal Equation p.134\n",
    "def GetTheNormalEquation(X, y):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Concatenate a column of ones to X\n",
    "    w = np.linalg.inv(X_b.T @ X_b) @ (X_b.T) @ (y)\n",
    "    return w\n",
    "\n",
    "def GenerateData():\n",
    "    X = np.array([[8.34044009e-01],[1.44064899e+00],[2.28749635e-04],[6.04665145e-01]])\n",
    "    y = np.array([5.97396028, 7.24897834, 4.86609388, 3.51245674])\n",
    "    return X, y\n",
    "\n",
    "X, y = GenerateData()\n",
    "\n",
    "w = GetTheNormalEquation(X, y)\n",
    "\n",
    "\n",
    "# TEST VECTOR:\n",
    "w_expected = np.array([4.046879011698, 1.880121487278])\n",
    "itmalutils.PrintMatrix(w, label=\"w=\", precision=12)\n",
    "itmalutils.AssertInRange(w, w_expected, eps=1E-9)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb Find the limits of the least-square method\n",
    "\n",
    "The problem with calculating of a matrix inverse can be compationally expensive. This is especially the case for larger or nearly singular matrices. A nearly singular matrix is one that is almost singular, which mean it does not have a true inverse. \n",
    "\n",
    "In the code below we have a function ` GenerateData(M, N)`. The given code The parameter M was set to 10000 instead of 1000, which provide a singular matrix and can not be calculated using the `GetTheNormalEquation(X, y)`\n",
    "\n",
    "The reason it takes such a long time is the computational complexity, meaning doubling the number of features then you have to multiply the computation time be rougly 2<sup>2.4</sup>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerateData(M=20, N=20)...\n",
      "w=[269350.4633123691       -1.043961801137  13245.210655669569\n",
      "   -14358.625316687934   4103.219677610949 -54576.86169321785\n",
      "   -62825.741479410775  58629.31752886504  -31491.158521367546\n",
      "     9715.601320183336   9953.192676909799 -75639.63251218229\n",
      "    18893.030828098854 -27811.057371811625  41429.10750189799\n",
      "     5856.683667406644 -14609.061829708258   3455.299372031989\n",
      "    -6726.860945640608  -7094.350019583393  33064.499321158684]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LienarRegression \n",
    "\n",
    "def GenerateData(M, N):\n",
    "    # TEST DATA: Matrix, taken from [HOML]\n",
    "    print(f'GenerateData(M={N}, N={N})...')\n",
    "    \n",
    "    assert M>0\n",
    "    assert N>0\n",
    "    assert isinstance(M, int)\n",
    "    assert isinstance(N, int)\n",
    "\n",
    "    # NOTE: not always possible to invert a random matrix; \n",
    "    #       it becomes sigular, hence a more elaborate choice \n",
    "    #       of values below (but still a hack): \n",
    "    X=2 * np.ones([M, N])\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i,0]=i*4\n",
    "    for j in range(X.shape[1]):\n",
    "        X[0,j]=-j*4\n",
    "\n",
    "    y=4 + 3*X + np.random.randn(M,1)\n",
    "    y=y[:,0] # well, could do better here!\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = GenerateData(M=1000, N=20)\n",
    "\n",
    "w = GetTheNormalEquation(X, y)\n",
    "\n",
    "# Print w\n",
    "itmalutils.PrintMatrix(w, label=\"w=\", precision=12)\n",
    "\n",
    "\n",
    "print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
